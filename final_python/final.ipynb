{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point, Polygon\n",
    "import googlemaps\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#city = \"Porto\"\n",
    "city = \"Lisboa\"\n",
    "if city == \"Porto\":\n",
    "    airbnb = pd.read_csv(\"data/airbnb/porto.csv\")\n",
    "    airbnb = airbnb[airbnb[\"neighbourhood_group\"] == \"PORTO\"]\n",
    "    gdf = gpd.read_file('data/geojson/porto.geojson')\n",
    "    joao = pd.read_csv(\"data/rnal/joao_rnal_porto.csv\", sep=\";\")\n",
    "elif city == \"Lisboa\":\n",
    "    airbnb = pd.read_csv(\"data/airbnb/lisboa.csv\")\n",
    "    airbnb = airbnb[airbnb[\"neighbourhood_group\"] == \"Lisboa\"]\n",
    "    gdf = gpd.read_file('data/geojson/lisboa.geojson')\n",
    "    joao = pd.read_csv(\"data/rnal/joao_rnal_lisboa.csv\")\n",
    "rnal = pd.read_csv(\"data/rnal/rnal_travelBI.csv\")\n",
    "\n",
    "polygon = gdf.geometry[0]\n",
    "def is_inside(row):\n",
    "    point = Point(row['X'], row['Y'])\n",
    "    return polygon.contains(point)\n",
    "    \n",
    "rnal['is_inside'] = rnal.apply(is_inside, axis=1)\n",
    "rnal = rnal[rnal['is_inside'] == True].drop(\"is_inside\", axis=1)\n",
    "rnal['DataAberturaPublico'] = rnal['DataAberturaPublico'].apply(lambda x: pd.to_datetime(x).date())\n",
    "rnal['DataRegisto'] = rnal['DataRegisto'].apply(lambda x: pd.to_datetime(x).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in rnal: 19318\n",
      "Number of data points in joao: 19151\n",
      "Number of data points in both rnal and joao: 19129\n",
      "Number of data points in joao but not in rnal: 22\n",
      "Number of data points in rnal but not in joao: 189\n"
     ]
    }
   ],
   "source": [
    "# Clean the NrRegisto column in joao\n",
    "joao['NrRegisto'] = joao['NrRegisto'].str.replace('/AL', '')\n",
    "\n",
    "# Convert NrRegisto to numeric to ensure proper comparison\n",
    "joao['NrRegisto'] = pd.to_numeric(joao['NrRegisto'], errors='coerce')\n",
    "\n",
    "# Find the data points in rnal that are not in joao\n",
    "rnal_not_in_joao = rnal[~rnal['NrRNAL'].isin(joao['NrRegisto'])]\n",
    "\n",
    "# Find the data points in joao that are not in rnal\n",
    "joao_not_in_rnal = joao[~joao['NrRegisto'].isin(rnal['NrRNAL'])]\n",
    "\n",
    "# Find the data points that are in both rnal and joao\n",
    "both_in_rnal_and_joao = rnal[rnal['NrRNAL'].isin(joao['NrRegisto'])]\n",
    "\n",
    "# Print the numbers\n",
    "print(\"Number of data points in rnal:\", rnal.shape[0])\n",
    "print(\"Number of data points in joao:\", joao.shape[0])\n",
    "print(\"Number of data points in both rnal and joao:\", both_in_rnal_and_joao.shape[0])\n",
    "print(\"Number of data points in joao but not in rnal:\", joao_not_in_rnal.shape[0])\n",
    "print(\"Number of data points in rnal but not in joao:\", rnal_not_in_joao.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnal['entradas_repetidas'] = rnal.groupby(['X', 'Y']).transform('size')\n",
    "min_value = rnal['entradas_repetidas'].min()\n",
    "max_value = rnal['entradas_repetidas'].max()\n",
    "rnal['weight'] = (rnal['entradas_repetidas'] - min_value) / (max_value - min_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listings from single hosts: 32.41%\n",
      "Listings from super hosts (>= 2): 67.59%\n",
      "Listings from mega hosts (>= 5): 41.88%\n"
     ]
    }
   ],
   "source": [
    "rnal['host_listings_number'] = rnal.groupby('Email')[\"NrRNAL\"].transform('count')\n",
    "percentage_single_hosts = (rnal['host_listings_number'] == 1).mean() * 100\n",
    "percentage_super_hosts = (rnal['host_listings_number'] >= 2).mean() * 100\n",
    "percentage_mega_hosts = (rnal['host_listings_number'] >= 5).mean() * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(f\"Listings from single hosts: {percentage_single_hosts:.2f}%\")\n",
    "print(f\"Listings from super hosts (>= 2): {percentage_super_hosts:.2f}%\")\n",
    "print(f\"Listings from mega hosts (>= 5): {percentage_mega_hosts:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the data points with entradas_repetidas > 1\n",
    "rnal_filtered = rnal[rnal['entradas_repetidas'] > 1]\n",
    "\n",
    "# For each group, keep only the one with the highest host_listings_number\n",
    "idx = rnal_filtered.groupby(['X', 'Y'])['host_listings_number'].idxmax()\n",
    "\n",
    "# Select the rows with the highest host_listings_number\n",
    "rnal_unique = rnal.loc[idx]\n",
    "\n",
    "# Combine with the data points where entradas_repetidas == 1\n",
    "rnal = pd.concat([rnal[rnal['entradas_repetidas'] == 1], rnal_unique])\n",
    "\n",
    "# Reset index if necessary\n",
    "rnal.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9804it [00:00, 22929.16it/s]\n"
     ]
    }
   ],
   "source": [
    "type_map = {'Apartamento':1,'Moradia':2,'EstabelecimentoHospedagem':3,'EstabelecimentoHospedagemHostel':4,'Quartos':5}\n",
    "freg_map_porto = {'União das freguesias de Cedofeita, Santo Ildefonso, Sé, Miragaia, São Nicolau e Vitória':1,'Bonfim':2,'União das freguesias de Lordelo do Ouro e Massarelos':3,'Paranhos':4,'União das freguesias de Aldoar, Foz do Douro e Nevogilde':5,'Campanhã':6,'Ramalde':7} \n",
    "freg_map_lisboa = {freg: idx for idx, freg in enumerate(rnal[\"Freguesia\"].unique(), start=1)}\n",
    "\n",
    "start_date = datetime(2011, 1, 1) # AL licenses start in 2011\n",
    "end_date = datetime(2024, 9, 25)\n",
    "\n",
    "geojson = {}\n",
    "geojson[\"type\"] = \"FeatureCollection\"\n",
    "geojson[\"features\"] = []\n",
    "\n",
    "for idx, single_al in tqdm(rnal.sort_values(by='host_listings_number', ascending = True).reset_index().iterrows()):\n",
    "    al_date = single_al.DataAberturaPublico\n",
    "    al_date = datetime.combine(al_date, datetime.min.time())\n",
    "    al_entry = {}\n",
    "    al_entry[\"type\"] = \"Feature\"\n",
    "    al_entry[\"properties\"] = {}\n",
    "    al_entry[\"properties\"][\"id\"] = idx+1\n",
    "    al_entry[\"properties\"][\"year\"] = al_date.strftime('%y')\n",
    "    al_entry[\"properties\"][\"month\"] = al_date.strftime('%m')\n",
    "    \n",
    "    january_2014 = datetime(2014, 1, 1)\n",
    "    # Calculate the difference in months between al_date and january_2014\n",
    "    months_diff = ((al_date.year - january_2014.year) * 12 + al_date.month - january_2014.month) / 128.0  # 113 months between January 2014 and September 2024\n",
    "    # Ensure the normalized variable is within the range [0, 1]\n",
    "    normalized_variable = max(0, min(1, months_diff))\n",
    "    al_entry[\"properties\"][\"normalized_date\"] = normalized_variable    \n",
    "    al_entry[\"properties\"][\"type\"] = type_map[single_al.Modalidade]\n",
    "    al_entry[\"properties\"][\"ts\"] = round(min(max((al_date - start_date).days / (end_date - start_date).days, 0), 1), 2)\n",
    "    if city == \"Porto\":\n",
    "        al_entry[\"properties\"][\"freg\"] = freg_map_porto[single_al.Freguesia]\n",
    "    elif city == \"Lisboa\":\n",
    "        al_entry[\"properties\"][\"freg\"] = freg_map_lisboa[single_al.Freguesia]\n",
    "    al_entry[\"properties\"][\"weight\"] = single_al.weight\n",
    "    al_entry[\"properties\"][\"endereco\"] = single_al.Endereco\n",
    "    al_entry[\"properties\"][\"entradas_repetidas\"] = single_al.entradas_repetidas\n",
    "    al_entry[\"properties\"][\"host_listings_number\"] = single_al.host_listings_number\n",
    "    al_entry[\"geometry\"] = {}\n",
    "    al_entry[\"geometry\"][\"type\"] = \"Point\"\n",
    "    al_entry[\"geometry\"][\"coordinates\"] = [round(single_al.X,6),round(single_al.Y,6)]\n",
    "    geojson[\"features\"].append(al_entry)\n",
    "\n",
    "if city == \"Porto\":\n",
    "    with open(f'al.json', 'w') as fp:\n",
    "        json.dump(geojson, fp, separators=(',', ':'))\n",
    "elif city == \"Lisboa\":\n",
    "    with open(f'al.json', 'w') as fp:\n",
    "        json.dump(geojson, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
