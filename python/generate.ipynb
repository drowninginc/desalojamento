{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point, Polygon\n",
    "import googlemaps\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "airbnb = pd.read_csv(\"data/csvs/airbnb_listings.csv\")\n",
    "airbnb = airbnb[airbnb[\"neighbourhood_group_cleansed\"] == \"PORTO\"]\n",
    "rnal = pd.read_csv('data/csvs/rnal_googlecoords.csv')\n",
    "rnet = pd.read_csv(\"data/csvs/rnet.csv\")\n",
    "gdf = gpd.read_file('data/geojson/porto.geojson')\n",
    "polygon = gdf.geometry[0]\n",
    "\n",
    "def is_inside(row):\n",
    "    point = Point(row['X'], row['Y'])\n",
    "    return polygon.contains(point)\n",
    "    \n",
    "rnal['is_inside'] = rnal.apply(is_inside, axis=1)\n",
    "rnal = rnal[rnal['is_inside'] == True].drop(\"is_inside\", axis=1)\n",
    "rnal['host_listings_number'] = rnal.groupby('Email')[\"NrRNAL\"].transform('count')\n",
    "rnal['mega_host'] = rnal['host_listings_number'] > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Coordenadas da Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    pattern0= r'^[^a-zA-Z]*'\n",
    "    result0 = re.sub(pattern0, '', input_string)\n",
    "    pattern1 = re.compile(r'\\b(\\w+)\\b\\s+\\1\\b')\n",
    "    result = re.sub(pattern1, r'\\1', result0)\n",
    "    #print(\"result: \" + result)\n",
    "    pattern2 = re.compile(r'\\d+')\n",
    "    match2 = pattern2.search(result)\n",
    "    #print(\"match2: \" + match2.group(0))\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    result = result.translate(translator).replace(' doutor ', ' dr ').replace(\" senhor \", \" sr \").replace(\" senhora \",\" sra \").replace(\" santo \", \" s \").replace(\" santa \",\" sta \").replace(\" das \",\" \").replace(\" dos \",\" \").replace(\" do \", \" \").replace(\" da \",\" \").replace(\" de \",\" \").replace(\"  \",\" \")\n",
    "    if match2:\n",
    "        pattern3 = r'^\\D*'  \n",
    "        match3 = re.search(pattern3, result)\n",
    "        #print(\"match3: \" + match3.group())\n",
    "        return match3.group() + match2.group(0)\n",
    "    elif result:\n",
    "        return result\n",
    "\n",
    "rnal[\"numero_porta\"] = rnal[\"Endereco\"].apply(clean_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, postalcode):\n",
    "    try:\n",
    "        if postalcode: \n",
    "            geocode_result = gmaps.geocode(f'{address} {postalcode} {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "        else:\n",
    "            geocode_result = gmaps.geocode(f'{address}, {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "\n",
    "        geocode_types = sum([i['types'] for i in geocode_result['address_components']], [])\n",
    "        \n",
    "        lat, lon = geocode_result['geometry']['location'].values()\n",
    "        \n",
    "        geocode_flag = not ('street_number' in geocode_types and 'route' in geocode_types)\n",
    "        polygon_flag = not city_polygon.contains(Point(lon, lat))\n",
    "        city_flag = (city_lat, city_lon) == (lat, lon)\n",
    "        \n",
    "        flag = geocode_flag or polygon_flag or city_flag\n",
    "        \n",
    "        return [lat, lon, flag]\n",
    "    except:\n",
    "        print(address)\n",
    "        print(postalcode)\n",
    "        print(city)\n",
    "        print(country)\n",
    "    return [np.nan, np.nan, True]\n",
    "\n",
    "KEY = 'AIzaSyCIzAbRgEsMKAzkUuos4oEEaeGtSJ_Kh58'\n",
    "gmaps = googlemaps.Client(key=KEY)\n",
    "city = 'Porto'\n",
    "country = 'Portugal'\n",
    "city_polygon = Polygon(requests.get(f'https://nominatim.openstreetmap.org/search.php?q={city}+{country}&polygon_geojson=1&format=json').json()[0]['geojson']['coordinates'][0])\n",
    "city_lat, city_lon = gmaps.geocode(f'{city}, {country})')[0]['geometry']['location'].values()\n",
    "\n",
    "city_coordinates = rnal.progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, x.CodigoPostal), index=['lat', 'lon', 'flag']), axis=1)\n",
    "rnal =  pd.concat([rnal[:], city_coordinates[:]], axis=\"columns\")\n",
    "\n",
    "rnal[\"flag\"] = rnal[\"flag\"].fillna(True)\n",
    "rnal[\"numero_porta\"] = rnal[\"numero_porta\"].apply(unidecode)\n",
    "city_coordinates = rnal[rnal.flag].progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, False), index=['lat', 'lon', 'flag']), axis=1)\n",
    "for idx, row in tqdm(city_coordinates.iterrows()):\n",
    "    rnal.loc[idx,['lat','lon','flag']] = [row.lat,row.lon,row.flag]\n",
    "\n",
    "rnal.loc[rnal['flag'], ['lat', 'lon']] = rnal.loc[rnal['flag'], ['Y', 'X']].values\n",
    "\n",
    "\n",
    "rnal[\"X\"] = rnal[\"lat\"].round(6)\n",
    "rnal[\"Y\"] = rnal[\"lon\"].round(6)\n",
    "rnal = rnal.drop(['flag', \"lat\", \"lon\"], axis=1)\n",
    "rnal['DataAberturaPublico'] = rnal['DataAberturaPublico'].apply(lambda x: pd.to_datetime(x).date())\n",
    "rnal['DataRegisto'] = rnal['DataRegisto'].apply(lambda x: pd.to_datetime(x).date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Como se expandiram os ALs ao longo do tempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_map = {'Apartamento':1,'Moradia':2,'EstabelecimentoHospedagem':3,'EstabelecimentoHospedagemHostel':4,'Quartos':5}\n",
    "freg_map = {'União das freguesias de Cedofeita, Santo Ildefonso, Sé, Miragaia, São Nicolau e Vitória':1,'Bonfim':2,'União das freguesias de Lordelo do Ouro e Massarelos':3,'Paranhos':4,'União das freguesias de Aldoar, Foz do Douro e Nevogilde':5,'Campanhã':6,'Ramalde':7}\n",
    "\n",
    "start_date = datetime(2011, 1, 1) # AL licenses start in 2011\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "al_json = []\n",
    "\n",
    "for idx, single_al in rnal.sort_values(by='DataAberturaPublico').reset_index().iterrows():\n",
    "    al_date = datetime.strptime(single_al.DataAberturaPublico[:-3], '%Y/%m/%d %H:%M:%S')\n",
    "    al_entry = {}\n",
    "    al_entry[\"id\"] = idx+1\n",
    "    al_entry[\"m\"] = al_date.strftime('%m')\n",
    "    al_entry[\"y\"] = al_date.strftime('%y')\n",
    "    al_entry[\"ts\"] = round(min(max((al_date - start_date).days / (end_date - start_date).days, 0), 1), 2)\n",
    "    al_entry[\"type\"] = type_map[single_al.Modalidade]\n",
    "    al_entry[\"freg\"] = freg_map[single_al.Freguesia] #TODO\n",
    "    al_entry[\"mega_host\"] = single_al.mega_host\n",
    "    al_entry[\"coord\"] = [round(single_al.X,6),round(single_al.Y,6)]\n",
    "    al_json.append(al_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/al.json', 'w') as fp:\n",
    "    json.dump(al_json, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quais as zonas de maior pressão?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Por secção estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/censos/BGRI.gpkg\"\n",
    "BGRI = gpd.read_file(input_file)\n",
    "BGRI = BGRI.to_crs(\"EPSG:4326\")\n",
    "points_gdf = gpd.GeoDataFrame(rnal, geometry=gpd.points_from_xy(rnal['X'], rnal['Y']), crs=\"EPSG:4326\")\n",
    "points_in_areas = gpd.sjoin(points_gdf, BGRI, how='left', op='within')\n",
    "point_counts = points_in_areas.groupby('BGRI2021').size().reset_index(name='ALs')\n",
    "merged_df = pd.merge(BGRI, point_counts, on='BGRI2021', how='left')\n",
    "merged_df['ALs'] = merged_df['ALs'].fillna(0)\n",
    "merged_df[\"ALs_ALsmaisAlojamentos\"] = merged_df[\"ALs\"] / (merged_df[\"N_ALOJAMENTOS_FAMILIARES\"] + merged_df[\"ALs\"])*100\n",
    "\n",
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "\n",
    "intersections = gpd.overlay(merged_df, CAOP11, how='intersection')\n",
    "intersections['intersection_area'] = intersections['geometry'].area\n",
    "idx = intersections.groupby('BGRI2021')['intersection_area'].idxmax()\n",
    "result_df = intersections.loc[idx, ['BGRI2021', 'FREGUESIA']]\n",
    "result_df[\"BGRI2021\"] = result_df[\"BGRI2021\"].astype(int)\n",
    "result_df = pd.DataFrame(result_df).set_index(\"BGRI2021\")\n",
    "merged_df[\"BGRI2021\"] = merged_df[\"BGRI2021\"].astype(int)\n",
    "merged_df = merged_df.set_index(\"BGRI2021\")\n",
    "result_df = result_df.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "result_df[\"Freguesia2011\"] = result_df[\"Freguesia2011\"].apply(str.title)\n",
    "merged_df = merged_df.join(result_df, on=\"BGRI2021\", how=\"left\")\n",
    "merged_df[\"Freguesia2011_code\"] = merged_df['Freguesia2011'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressao_json_seccao = []\n",
    "\n",
    "for idx, single_block in merged_df.reset_index().iterrows():\n",
    "    censos_entry = {}\n",
    "    censos_entry[\"geo\"] = single_block.geometry\n",
    "    censos_entry[\"als\"] = single_block.ALs\n",
    "    censos_entry[\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"freg\"] = single_block.Freguesia2011_code\n",
    "    censos_json.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos.json', 'w') as fp:\n",
    "    json.dump(pressao_json_seccao, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Por Freguesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "CAOP11 = pd.DataFrame(CAOP11)\n",
    "CAOP11[\"FREGUESIA\"] = CAOP11[\"FREGUESIA\"].apply(str.title)\n",
    "CAOP11 = CAOP11.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "CAOP11 = CAOP11.set_index(\"Freguesia2011\")\n",
    "\n",
    "freguesias = merged_df.groupby(\"Freguesia2011\").agg({\"Freguesia2011_code\":\"first\", \"N_INDIVIDUOS\":'sum', \"ALs\":\"sum\", \"N_ALOJAMENTOS_FAMILIARES\":\"sum\"})\n",
    "freguesias[\"ALs_ALsmaisAlojamentos\"] = freguesias[\"ALs\"] / (freguesias[\"N_ALOJAMENTOS_FAMILIARES\"] + freguesias[\"ALs\"])*100\n",
    "freguesias = freguesias.join(CAOP11, on=\"Freguesia2011\", how=\"left\")\n",
    "freguesias.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressao_json_freguesia = []\n",
    "\n",
    "for idx, single_block in freguesias.reset_index().iterrows():\n",
    "    censos_entry = {}\n",
    "    censos_entry[\"geo\"] = single_block.geometry\n",
    "    censos_entry[\"als\"] = single_block.ALs\n",
    "    censos_entry[\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"freg\"] = single_block.Freguesia2011_code\n",
    "    censos_json.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos.json', 'w') as fp:\n",
    "    json.dump(pressao_json_freguesia, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este bloco é para quê?\n",
    "\n",
    "from shapely.wkt import loads, dumps\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "def round_coordinates(geom, decimal_places=6):\n",
    "    geojson = mapping(geom)\n",
    "    def round_recursive(coord_list):\n",
    "        if isinstance(coord_list[0], list):  # If the item is another list, recurse\n",
    "            return [round_recursive(sublist) for sublist in coord_list]\n",
    "        else:\n",
    "            # Handling the rounding of each coordinate separately\n",
    "            return [round(coord, decimal_places) for coord in coord_list]\n",
    "    geojson['coordinates'] = round_recursive(geojson['coordinates'])\n",
    "    return shape(geojson)\n",
    "\n",
    "# Provided MULTIPOLYGON string\n",
    "multipolygon_str = 'MULTIPOLYGON (((-8.599050830471858 41.1704689632344, -8.599475270156416 41.170491995655034, -8.599391251759887 41.170993532906024, -8.599361103057639 41.17101183468953, -8.599324655382437 41.171020733530575, -8.598995758801557 41.17105866692871, -8.599050830471858 41.1704689632344)))'\n",
    "\n",
    "# Convert the string to a Shapely geometry\n",
    "geom = loads(multipolygon_str)\n",
    "\n",
    "# Round the coordinates\n",
    "rounded_geom = round_coordinates(geom, decimal_places=6)\n",
    "\n",
    "# Convert the Shapely geometry back to a string\n",
    "rounded_str = dumps(rounded_geom)\n",
    "\n",
    "# Print or utilize the rounded string\n",
    "print(rounded_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping(geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quem ganha com os ALs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Concentração económica (ALs por host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['host_listings_number'] = airbnb.groupby('host_id')['listing_url'].transform('count')\n",
    "airbnb[\"host_more_than_1_listing\"] = airbnb['host_listings_number'].apply(lambda x: x > 1)\n",
    "airbnb[\"host_more_than_2_listings\"] = airbnb['host_listings_number'].apply(lambda x: x > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts Airbnb: 3309\n",
      "Número de hosts com 2 ou mais anúncios: 1326\n",
      "Número de hosts com 3 ou mais anúncios: 887\n"
     ]
    }
   ],
   "source": [
    "host_listings_count = airbnb['host_id'].value_counts().reset_index()\n",
    "host_listings_count.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts Airbnb: \" + str(host_listings_count[host_listings_count[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts RNAL: 4331\n",
      "Número de hosts com 2 ou mais anúncios: 1383\n",
      "Número de hosts com 3 ou mais anúncios: 812\n"
     ]
    }
   ],
   "source": [
    "host_listings_count_rnal = rnal[\"Email\"].value_counts().reset_index()\n",
    "host_listings_count_rnal.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts RNAL: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prédios com vários ALs (só funcionará quando corrermos API do Google Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnal['entradas_repetidas'] = rnal.groupby(['X', 'Y']).transform('size')\n",
    "rnal[[\"numero_porta\",\"entradas_repetidas\"]].drop_duplicates().sort_values(by=\"entradas_repetidas\", ascending=False).set_index(\"numero_porta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Licenças "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_license\n",
       "RNAL    8164\n",
       "None    1661\n",
       "RNET      91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_code(text):\n",
    "    # Use regular expression to find and extract all groups of consecutive numbers\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    \n",
    "    # Find the largest group of consecutive numbers (if any)\n",
    "    if numbers:\n",
    "        largest_number = max(numbers, key=len)\n",
    "        return largest_number\n",
    "    return None\n",
    "airbnb[\"license\"] = airbnb[\"license\"].astype(str)\n",
    "airbnb['license_cleaned'] = airbnb['license'].apply(extract_code)\n",
    "airbnb[\"license_cleaned\"] = airbnb[\"license_cleaned\"].replace({\"6\":\"0\",\n",
    "\"Registo n.º: 237/2010 (4 de Maio) - Turismo Portugal\":\"237\",\n",
    "\"553/2016\":\"553\"})\n",
    "\n",
    "rnal[\"NrRNAL\"] = rnal[\"NrRNAL\"].astype(str)\n",
    "rnet[\"NrRNET\"] = rnet[\"NrRNET\"].astype(str)\n",
    "set_rnal = set(rnal[\"NrRNAL\"])\n",
    "set_rnet = set(rnet[\"NrRNET\"])\n",
    "\n",
    "def has_license(license_number):\n",
    "    if license_number in set_rnal:\n",
    "        return 'RNAL'\n",
    "    elif license_number in set_rnet:\n",
    "        return 'RNET'\n",
    "    else:\n",
    "        return 'None'\n",
    "        \n",
    "airbnb['has_license'] = airbnb['license_cleaned'].apply(has_license)\n",
    "airbnb['has_license'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anúncios sem indicação de licença: 838\n"
     ]
    }
   ],
   "source": [
    "print(\"Anúncios sem indicação de licença: \" + str(airbnb['license_cleaned'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "license_date_after_review\n",
       "False    6252\n",
       "True     1275\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_with_RNAL = airbnb[airbnb[\"has_license\"] == \"RNAL\"][[\"license_cleaned\",\"first_review\"]]\n",
    "airbnb_with_RNAL = airbnb_with_RNAL.rename(columns={\"license_cleaned\":\"NrRNAL\"})\n",
    "\n",
    "merged_airbnb_RNAL = rnal.merge(airbnb_with_RNAL, on='NrRNAL', how='inner')\n",
    "merged_airbnb_RNAL = merged_airbnb_RNAL[~merged_airbnb_RNAL[\"first_review\"].isna()]\n",
    "merged_airbnb_RNAL.shape\n",
    "\n",
    "merged_airbnb_RNAL['DataAberturaPublico'] = pd.to_datetime(merged_airbnb_RNAL['DataAberturaPublico'])\n",
    "merged_airbnb_RNAL['first_review'] = pd.to_datetime(merged_airbnb_RNAL['first_review'])\n",
    "merged_airbnb_RNAL['first_review'] = merged_airbnb_RNAL['first_review'].dt.tz_localize('UTC')\n",
    "\n",
    "merged_airbnb_RNAL['license_date_after_review'] = merged_airbnb_RNAL['DataAberturaPublico'] > merged_airbnb_RNAL['first_review']\n",
    "merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airbnbs com reviews anteriores à data de abertura: 1275\n"
     ]
    }
   ],
   "source": [
    "print(\"Airbnbs com reviews anteriores à data de abertura: \" + str(merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()[True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = pd.read_csv('../Hoteis/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "geojson = {}\n",
    "geojson[\"type\"] = \"FeatureCollection\"\n",
    "geojson[\"features\"] = []\n",
    "\n",
    "for idx, single_hotel in hotels.reset_index().iterrows():\n",
    "    hotel_entry = {}\n",
    "    hotel_entry[\"type\"] = \"Feature\"\n",
    "    hotel_entry[\"geometry\"] = json.loads(single_hotel.geometry.replace(\"\\'\", \"\\\"\"))\n",
    "    hotel_entry[\"properties\"] = {}\n",
    "    hotel_entry[\"properties\"][\"h\"] = single_hotel.novos_ET\n",
    "    geojson[\"features\"].append(hotel_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/hotels.json', 'w') as fp:\n",
    "    json.dump(geojson, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
