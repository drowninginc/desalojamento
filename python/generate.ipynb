{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import googlemaps\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "airbnb = pd.read_csv(\"data/csvs/airbnb_listings.csv\")\n",
    "airbnb = airbnb[airbnb[\"neighbourhood_group_cleansed\"] == \"PORTO\"]\n",
    "rnal = pd.read_csv('data/csvs/rnal_googlecoords.csv')\n",
    "rnet = pd.read_csv(\"data/csvs/rnet.csv\")\n",
    "gdf = gpd.read_file('data/geojson/porto.geojson')\n",
    "polygon = gdf.geometry[0]\n",
    "\n",
    "def is_inside(row):\n",
    "    point = Point(row['X'], row['Y'])\n",
    "    return polygon.contains(point)\n",
    "    \n",
    "rnal['is_inside'] = rnal.apply(is_inside, axis=1)\n",
    "rnal = rnal[rnal['is_inside'] == True].drop(\"is_inside\", axis=1)\n",
    "rnal['host_listings_number'] = rnal.groupby('Email')[\"NrRNAL\"].transform('count')\n",
    "rnal['mega_host'] = rnal['host_listings_number'] > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Coordenadas da Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    pattern0= r'^[^a-zA-Z]*'\n",
    "    result0 = re.sub(pattern0, '', input_string)\n",
    "    pattern1 = re.compile(r'\\b(\\w+)\\b\\s+\\1\\b')\n",
    "    result = re.sub(pattern1, r'\\1', result0)\n",
    "    #print(\"result: \" + result)\n",
    "    pattern2 = re.compile(r'\\d+')\n",
    "    match2 = pattern2.search(result)\n",
    "    #print(\"match2: \" + match2.group(0))\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    result = result.translate(translator).replace(' doutor ', ' dr ').replace(\" senhor \", \" sr \").replace(\" senhora \",\" sra \").replace(\" santo \", \" s \").replace(\" santa \",\" sta \").replace(\" das \",\" \").replace(\" dos \",\" \").replace(\" do \", \" \").replace(\" da \",\" \").replace(\" de \",\" \").replace(\"  \",\" \")\n",
    "    if match2:\n",
    "        pattern3 = r'^\\D*'  \n",
    "        match3 = re.search(pattern3, result)\n",
    "        #print(\"match3: \" + match3.group())\n",
    "        return match3.group() + match2.group(0)\n",
    "    elif result:\n",
    "        return result\n",
    "\n",
    "rnal[\"numero_porta\"] = rnal[\"Endereco\"].apply(clean_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, postalcode):\n",
    "    try:\n",
    "        if postalcode: \n",
    "            geocode_result = gmaps.geocode(f'{address} {postalcode} {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "        else:\n",
    "            geocode_result = gmaps.geocode(f'{address}, {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "\n",
    "        geocode_types = sum([i['types'] for i in geocode_result['address_components']], [])\n",
    "        \n",
    "        lat, lon = geocode_result['geometry']['location'].values()\n",
    "        \n",
    "        geocode_flag = not ('street_number' in geocode_types and 'route' in geocode_types)\n",
    "        polygon_flag = not city_polygon.contains(Point(lon, lat))\n",
    "        city_flag = (city_lat, city_lon) == (lat, lon)\n",
    "        \n",
    "        flag = geocode_flag or polygon_flag or city_flag\n",
    "        \n",
    "        return [lat, lon, flag]\n",
    "    except:\n",
    "        print(address)\n",
    "        print(postalcode)\n",
    "        print(city)\n",
    "        print(country)\n",
    "    return [np.nan, np.nan, True]\n",
    "\n",
    "KEY = 'AIzaSyCIzAbRgEsMKAzkUuos4oEEaeGtSJ_Kh58'\n",
    "gmaps = googlemaps.Client(key=KEY)\n",
    "city = 'Porto'\n",
    "country = 'Portugal'\n",
    "city_polygon = Polygon(requests.get(f'https://nominatim.openstreetmap.org/search.php?q={city}+{country}&polygon_geojson=1&format=json').json()[0]['geojson']['coordinates'][0])\n",
    "city_lat, city_lon = gmaps.geocode(f'{city}, {country})')[0]['geometry']['location'].values()\n",
    "\n",
    "city_coordinates = rnal.progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, x.CodigoPostal), index=['lat', 'lon', 'flag']), axis=1)\n",
    "rnal =  pd.concat([rnal[:], city_coordinates[:]], axis=\"columns\")\n",
    "\n",
    "rnal[\"flag\"] = rnal[\"flag\"].fillna(True)\n",
    "rnal[\"numero_porta\"] = rnal[\"numero_porta\"].apply(unidecode)\n",
    "city_coordinates = rnal[rnal.flag].progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, False), index=['lat', 'lon', 'flag']), axis=1)\n",
    "for idx, row in tqdm(city_coordinates.iterrows()):\n",
    "    rnal.loc[idx,['lat','lon','flag']] = [row.lat,row.lon,row.flag]\n",
    "\n",
    "rnal.loc[rnal['flag'], ['lat', 'lon']] = rnal.loc[rnal['flag'], ['Y', 'X']].values\n",
    "\n",
    "\n",
    "rnal[\"X\"] = rnal[\"lat\"].round(6)\n",
    "rnal[\"Y\"] = rnal[\"lon\"].round(6)\n",
    "rnal = rnal.drop(['flag', \"lat\", \"lon\"], axis=1)\n",
    "rnal['DataAberturaPublico'] = rnal['DataAberturaPublico'].apply(lambda x: pd.to_datetime(x).date())\n",
    "rnal['DataRegisto'] = rnal['DataRegisto'].apply(lambda x: pd.to_datetime(x).date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Como se expandiram os ALs ao longo do tempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_map = {'Apartamento':1,'Moradia':2,'EstabelecimentoHospedagem':3,'EstabelecimentoHospedagemHostel':4,'Quartos':5}\n",
    "freg_map = {'União das freguesias de Cedofeita, Santo Ildefonso, Sé, Miragaia, São Nicolau e Vitória':1,'Bonfim':2,'União das freguesias de Lordelo do Ouro e Massarelos':3,'Paranhos':4,'União das freguesias de Aldoar, Foz do Douro e Nevogilde':5,'Campanhã':6,'Ramalde':7}\n",
    "\n",
    "start_date = datetime(2011, 1, 1) # AL licenses start in 2011\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "al_json = []\n",
    "\n",
    "for idx, single_al in rnal.sort_values(by='DataAberturaPublico').reset_index().iterrows():\n",
    "    al_date = datetime.strptime(single_al.DataAberturaPublico[:-3], '%Y/%m/%d %H:%M:%S')\n",
    "    al_entry = {}\n",
    "    al_entry[\"id\"] = idx+1\n",
    "    al_entry[\"m\"] = al_date.strftime('%m')\n",
    "    al_entry[\"y\"] = al_date.strftime('%y')\n",
    "    al_entry[\"ts\"] = round(min(max((al_date - start_date).days / (end_date - start_date).days, 0), 1), 2)\n",
    "    al_entry[\"type\"] = type_map[single_al.Modalidade]\n",
    "    al_entry[\"freg\"] = freg_map[single_al.Freguesia] #TODO\n",
    "    al_entry[\"mega_host\"] = single_al.mega_host\n",
    "    al_entry[\"coord\"] = [round(single_al.X,6),round(single_al.Y,6)]\n",
    "    al_json.append(al_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/al.json', 'w') as fp:\n",
    "    json.dump(al_json, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quais as zonas de maior pressão?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Por secção estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.wkt import loads, dumps\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "def round_coordinates(geometry, precision=6):\n",
    "    def round_coords(coords):\n",
    "        return round(coords, precision)\n",
    "\n",
    "    if isinstance(geometry, Point):\n",
    "        return dumps(Point(round_coords(geometry.x), round_coords(geometry.y)))\n",
    "    elif isinstance(geometry, Polygon):\n",
    "        exterior = [round_coords(coord) for coord in geometry.exterior.coords]\n",
    "        interior = [[round_coords(coord) for coord in ring.coords] for ring in geometry.interiors]\n",
    "        return dumps(Polygon(exterior, interior))\n",
    "    elif isinstance(geometry, MultiPolygon):\n",
    "        polygons = [round_coordinates(poly, precision) for poly in geometry.geoms]\n",
    "        return dumps(MultiPolygon(polygons))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported geometry type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/ipython/libexec/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3488: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/opt/homebrew/Cellar/jupyterlab/4.0.8_1/libexec/lib/python3.12/site-packages/geopandas/geodataframe.py:1815: FutureWarning: `unary_union` returned None due to all-None GeoSeries. In future, `unary_union` will return 'GEOMETRYCOLLECTION EMPTY' instead.\n",
      "  merged_geom = block.unary_union\n",
      "/var/folders/2_/dc69y37n7d14q5rbg8ly14g40000gn/T/ipykernel_4582/2102531174.py:16: UserWarning: `keep_geom_type=True` in overlay resulted in 449 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  intersections = gpd.overlay(merged_df, CAOP11, how='intersection')\n",
      "/var/folders/2_/dc69y37n7d14q5rbg8ly14g40000gn/T/ipykernel_4582/2102531174.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersections['intersection_area'] = intersections['geometry'].area\n"
     ]
    }
   ],
   "source": [
    "input_file = \"data/censos/BGRI.gpkg\"\n",
    "BGRI = gpd.read_file(input_file)\n",
    "BGRI = BGRI.to_crs(\"EPSG:4326\")\n",
    "points_gdf = gpd.GeoDataFrame(rnal, geometry=gpd.points_from_xy(rnal['X'], rnal['Y']), crs=\"EPSG:4326\")\n",
    "points_in_areas = gpd.sjoin(points_gdf, BGRI, how='left', op='within')\n",
    "point_counts = points_in_areas.groupby('BGRI2021').size().reset_index(name='ALs')\n",
    "merged_df = pd.merge(BGRI, point_counts, on='BGRI2021', how='left')\n",
    "merged_df['ALs'] = merged_df['ALs'].fillna(0)\n",
    "merged_df[\"ALs_ALsmaisAlojamentos\"] = merged_df[\"ALs\"] / (merged_df[\"N_ALOJAMENTOS_FAMILIARES\"] + merged_df[\"ALs\"])*100\n",
    "\n",
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "\n",
    "intersections = gpd.overlay(merged_df, CAOP11, how='intersection')\n",
    "intersections['intersection_area'] = intersections['geometry'].area\n",
    "idx = intersections.groupby('BGRI2021')['intersection_area'].idxmax()\n",
    "result_df = intersections.loc[idx, ['BGRI2021', 'FREGUESIA']]\n",
    "result_df[\"BGRI2021\"] = result_df[\"BGRI2021\"].astype(int)\n",
    "result_df = pd.DataFrame(result_df).set_index(\"BGRI2021\")\n",
    "merged_df[\"BGRI2021\"] = merged_df[\"BGRI2021\"].astype(int)\n",
    "merged_df = merged_df.set_index(\"BGRI2021\")\n",
    "result_df = result_df.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "result_df[\"Freguesia2011\"] = result_df[\"Freguesia2011\"].apply(str.title)\n",
    "merged_df = merged_df.join(result_df, on=\"BGRI2021\", how=\"left\")\n",
    "merged_df[\"Freguesia2011_code\"] = merged_df['Freguesia2011'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type array.array doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, single_block \u001b[38;5;129;01min\u001b[39;00m merged_df\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m     censos_entry \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 5\u001b[0m     censos_entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mround_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     censos_entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m single_block\u001b[38;5;241m.\u001b[39mALs\n\u001b[1;32m      7\u001b[0m     censos_entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividuos\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m single_block\u001b[38;5;241m.\u001b[39mN_INDIVIDUOS\n",
      "Cell \u001b[0;32mIn[90], line 25\u001b[0m, in \u001b[0;36mround_coordinates\u001b[0;34m(geom, decimal_places)\u001b[0m\n\u001b[1;32m     23\u001b[0m     geojson[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m round_polygon_coordinates(geom)\u001b[38;5;241m.\u001b[39mexterior\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mxy\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m geometry_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultipolygon\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     geojson[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mround_multipolygon_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgeoms]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported geometry type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(geometry_type))\n",
      "Cell \u001b[0;32mIn[90], line 17\u001b[0m, in \u001b[0;36mround_coordinates.<locals>.round_multipolygon_coordinates\u001b[0;34m(multipolygon)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround_multipolygon_coordinates\u001b[39m(multipolygon):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MultiPolygon([\u001b[43mround_polygon_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m polygon \u001b[38;5;129;01min\u001b[39;00m multipolygon\u001b[38;5;241m.\u001b[39mgeoms])\n",
      "Cell \u001b[0;32mIn[90], line 12\u001b[0m, in \u001b[0;36mround_coordinates.<locals>.round_polygon_coordinates\u001b[0;34m(polygon)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround_polygon_coordinates\u001b[39m(polygon):\n\u001b[0;32m---> 12\u001b[0m     exterior_coords \u001b[38;5;241m=\u001b[39m \u001b[43mround_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     interior_coords \u001b[38;5;241m=\u001b[39m [round_recursive(interior\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mxy) \u001b[38;5;28;01mfor\u001b[39;00m interior \u001b[38;5;129;01min\u001b[39;00m polygon\u001b[38;5;241m.\u001b[39minteriors]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Polygon(shell\u001b[38;5;241m=\u001b[39mexterior_coords, holes\u001b[38;5;241m=\u001b[39minterior_coords)\n",
      "Cell \u001b[0;32mIn[90], line 7\u001b[0m, in \u001b[0;36mround_coordinates.<locals>.round_recursive\u001b[0;34m(coord)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround_recursive\u001b[39m(coord):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(coord, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mround_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubcoord\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m subcoord \u001b[38;5;129;01min\u001b[39;00m coord]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mround\u001b[39m(coord, decimal_places)\n",
      "Cell \u001b[0;32mIn[90], line 9\u001b[0m, in \u001b[0;36mround_coordinates.<locals>.round_recursive\u001b[0;34m(coord)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [round_recursive(subcoord) \u001b[38;5;28;01mfor\u001b[39;00m subcoord \u001b[38;5;129;01min\u001b[39;00m coord]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal_places\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: type array.array doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "pressao_json_seccao = []\n",
    "\n",
    "for idx, single_block in merged_df.reset_index().iterrows():\n",
    "    censos_entry = {}\n",
    "    censos_entry[\"geo\"] = round_coordinates(single_block.geometry)\n",
    "    censos_entry[\"als\"] = single_block.ALs\n",
    "    censos_entry[\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"freg\"] = single_block.Freguesia2011_code\n",
    "    pressao_json_seccao.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos_seccao.json', 'w') as fp:\n",
    "    json.dump(pressao_json_seccao, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "\n",
    "P = shapely.wkt.loads(\"MULTIPOLYGON (((-8.619215409378157 41.17106299331059, -8.61850078470544 41.17066121680701, -8.61770007451112 41.17009121816355, -8.617584947421259 41.16996740405981, -8.618625915912292 41.16939539709438, -8.619944706915518 41.17040858438167, -8.620082696880752 41.17038028484132, -8.620176042462527 41.170747817643715, -8.619426093855445 41.17123502207297, -8.619215409378157 41.17106299331059)))\")\n",
    "\n",
    "round_coordinates(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Por Freguesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "CAOP11 = pd.DataFrame(CAOP11)\n",
    "CAOP11[\"FREGUESIA\"] = CAOP11[\"FREGUESIA\"].apply(str.title)\n",
    "CAOP11 = CAOP11.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "CAOP11 = CAOP11.set_index(\"Freguesia2011\")\n",
    "\n",
    "freguesias = merged_df.groupby(\"Freguesia2011\").agg({\"Freguesia2011_code\":\"first\", \"N_INDIVIDUOS\":'sum', \"ALs\":\"sum\", \"N_ALOJAMENTOS_FAMILIARES\":\"sum\"})\n",
    "freguesias[\"ALs_ALsmaisAlojamentos\"] = freguesias[\"ALs\"] / (freguesias[\"N_ALOJAMENTOS_FAMILIARES\"] + freguesias[\"ALs\"])*100\n",
    "freguesias = freguesias.join(CAOP11, on=\"Freguesia2011\", how=\"left\")\n",
    "freguesias.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressao_json_freguesia = []\n",
    "\n",
    "for idx, single_block in freguesias.reset_index().iterrows():\n",
    "    censos_entry = {}\n",
    "    censos_entry[\"geo\"] = single_block.geometry\n",
    "    censos_entry[\"als\"] = single_block.ALs\n",
    "    censos_entry[\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"freg\"] = single_block.Freguesia2011_code\n",
    "    censos_json.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos.json', 'w') as fp:\n",
    "    json.dump(pressao_json_freguesia, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este bloco é para quê?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping(geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quem ganha com os ALs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Concentração económica (ALs por host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['host_listings_number'] = airbnb.groupby('host_id')['listing_url'].transform('count')\n",
    "airbnb[\"host_more_than_1_listing\"] = airbnb['host_listings_number'].apply(lambda x: x > 1)\n",
    "airbnb[\"host_more_than_2_listings\"] = airbnb['host_listings_number'].apply(lambda x: x > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts Airbnb: 3309\n",
      "Número de hosts com 2 ou mais anúncios: 1326\n",
      "Número de hosts com 3 ou mais anúncios: 887\n"
     ]
    }
   ],
   "source": [
    "host_listings_count = airbnb['host_id'].value_counts().reset_index()\n",
    "host_listings_count.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts Airbnb: \" + str(host_listings_count[host_listings_count[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts RNAL: 4331\n",
      "Número de hosts com 2 ou mais anúncios: 1383\n",
      "Número de hosts com 3 ou mais anúncios: 812\n"
     ]
    }
   ],
   "source": [
    "host_listings_count_rnal = rnal[\"Email\"].value_counts().reset_index()\n",
    "host_listings_count_rnal.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts RNAL: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prédios com vários ALs (só funcionará quando corrermos API do Google Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entradas_repetidas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numero_porta</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rua dr emilio peres 74</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua joao regras 45</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua fernandes tomas 424</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua bonjardim 541</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua nova sao crispim 382</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua anselmo braamcamp 163</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua dr ricardo jorge 96</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua sra dores 122</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua dr dr ricardo jorge 96</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua flores 89</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua 5</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua alexandre herculano 352</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campo 24</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua flores 45</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua ceuta 44</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua camara pestana 330</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua almada 261</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua almada 551</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua entreparedes 62</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua jaime brasil 104</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             entradas_repetidas\n",
       "numero_porta                                   \n",
       "rua dr emilio peres 74                       70\n",
       "rua joao regras 45                           46\n",
       "rua fernandes tomas 424                      43\n",
       "rua bonjardim 541                            38\n",
       "rua nova sao crispim 382                     28\n",
       "rua anselmo braamcamp 163                    28\n",
       "rua dr ricardo jorge 96                      25\n",
       "rua sra dores 122                            25\n",
       "rua dr dr ricardo jorge 96                   25\n",
       "rua flores 89                                24\n",
       "rua 5                                        24\n",
       "rua alexandre herculano 352                  23\n",
       "campo 24                                     22\n",
       "rua flores 45                                22\n",
       "rua ceuta 44                                 20\n",
       "rua camara pestana 330                       19\n",
       "rua almada 261                               18\n",
       "rua almada 551                               18\n",
       "rua entreparedes 62                          18\n",
       "rua jaime brasil 104                         17"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rnal['entradas_repetidas'] = rnal.groupby(['X', 'Y']).transform('size')\n",
    "rnal[[\"numero_porta\",\"entradas_repetidas\"]].drop_duplicates().sort_values(by=\"entradas_repetidas\", ascending=False).set_index(\"numero_porta\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Licenças "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_license\n",
       "RNAL    8164\n",
       "None    1661\n",
       "RNET      91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_code(text):\n",
    "    # Use regular expression to find and extract all groups of consecutive numbers\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    \n",
    "    # Find the largest group of consecutive numbers (if any)\n",
    "    if numbers:\n",
    "        largest_number = max(numbers, key=len)\n",
    "        return largest_number\n",
    "    return None\n",
    "airbnb[\"license\"] = airbnb[\"license\"].astype(str)\n",
    "airbnb['license_cleaned'] = airbnb['license'].apply(extract_code)\n",
    "airbnb[\"license_cleaned\"] = airbnb[\"license_cleaned\"].replace({\"6\":\"0\",\n",
    "\"Registo n.º: 237/2010 (4 de Maio) - Turismo Portugal\":\"237\",\n",
    "\"553/2016\":\"553\"})\n",
    "\n",
    "rnal[\"NrRNAL\"] = rnal[\"NrRNAL\"].astype(str)\n",
    "rnet[\"NrRNET\"] = rnet[\"NrRNET\"].astype(str)\n",
    "set_rnal = set(rnal[\"NrRNAL\"])\n",
    "set_rnet = set(rnet[\"NrRNET\"])\n",
    "\n",
    "def has_license(license_number):\n",
    "    if license_number in set_rnal:\n",
    "        return 'RNAL'\n",
    "    elif license_number in set_rnet:\n",
    "        return 'RNET'\n",
    "    else:\n",
    "        return 'None'\n",
    "        \n",
    "airbnb['has_license'] = airbnb['license_cleaned'].apply(has_license)\n",
    "airbnb['has_license'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anúncios sem indicação de licença: 838\n"
     ]
    }
   ],
   "source": [
    "print(\"Anúncios sem indicação de licença: \" + str(airbnb['license_cleaned'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "license_date_after_review\n",
       "False    6252\n",
       "True     1275\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_with_RNAL = airbnb[airbnb[\"has_license\"] == \"RNAL\"][[\"license_cleaned\",\"first_review\"]]\n",
    "airbnb_with_RNAL = airbnb_with_RNAL.rename(columns={\"license_cleaned\":\"NrRNAL\"})\n",
    "\n",
    "merged_airbnb_RNAL = rnal.merge(airbnb_with_RNAL, on='NrRNAL', how='inner')\n",
    "merged_airbnb_RNAL = merged_airbnb_RNAL[~merged_airbnb_RNAL[\"first_review\"].isna()]\n",
    "merged_airbnb_RNAL.shape\n",
    "\n",
    "merged_airbnb_RNAL['DataAberturaPublico'] = pd.to_datetime(merged_airbnb_RNAL['DataAberturaPublico'])\n",
    "merged_airbnb_RNAL['first_review'] = pd.to_datetime(merged_airbnb_RNAL['first_review'])\n",
    "merged_airbnb_RNAL['first_review'] = merged_airbnb_RNAL['first_review'].dt.tz_localize('UTC')\n",
    "\n",
    "merged_airbnb_RNAL['license_date_after_review'] = merged_airbnb_RNAL['DataAberturaPublico'] > merged_airbnb_RNAL['first_review']\n",
    "merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airbnbs com reviews anteriores à data de abertura: 1275\n"
     ]
    }
   ],
   "source": [
    "print(\"Airbnbs com reviews anteriores à data de abertura: \" + str(merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()[True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = pd.read_csv('../Hoteis/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "geojson = {}\n",
    "geojson[\"type\"] = \"FeatureCollection\"\n",
    "geojson[\"features\"] = []\n",
    "\n",
    "for idx, single_hotel in hotels.reset_index().iterrows():\n",
    "    hotel_entry = {}\n",
    "    hotel_entry[\"type\"] = \"Feature\"\n",
    "    hotel_entry[\"geometry\"] = json.loads(single_hotel.geometry.replace(\"\\'\", \"\\\"\"))\n",
    "    hotel_entry[\"properties\"] = {}\n",
    "    hotel_entry[\"properties\"][\"h\"] = single_hotel.novos_ET\n",
    "    geojson[\"features\"].append(hotel_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/hotels.json', 'w') as fp:\n",
    "    json.dump(geojson, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
