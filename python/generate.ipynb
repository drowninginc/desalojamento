{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.8_1/libexec/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import googlemaps\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from shapely.wkt import loads, dumps\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "airbnb = pd.read_csv(\"data/csvs/airbnb_listings.csv\")\n",
    "airbnb = airbnb[airbnb[\"neighbourhood_group_cleansed\"] == \"PORTO\"]\n",
    "rnal_original = pd.read_csv(\"data/csvs/rnal.csv\")\n",
    "rnal = pd.read_csv(\"data/csvs/rnal_googlemaps.csv\")\n",
    "rnet = pd.read_csv(\"data/csvs/rnet.csv\")\n",
    "gdf = gpd.read_file('data/geojson/porto.geojson')\n",
    "polygon = gdf.geometry[0]\n",
    "\n",
    "def is_inside(row):\n",
    "    point = Point(row['X'], row['Y'])\n",
    "    return polygon.contains(point)\n",
    "    \n",
    "rnal['is_inside'] = rnal.apply(is_inside, axis=1)\n",
    "rnal = rnal[rnal['is_inside'] == True].drop(\"is_inside\", axis=1)\n",
    "rnal['host_listings_number'] = rnal.groupby('Email')[\"NrRNAL\"].transform('count')\n",
    "rnal['mega_host'] = rnal['host_listings_number'] > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Coordenadas da Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    pattern0= r'^[^a-zA-Z]*'\n",
    "    result0 = re.sub(pattern0, '', input_string)\n",
    "    pattern1 = re.compile(r'\\b(\\w+)\\b\\s+\\1\\b')\n",
    "    result = re.sub(pattern1, r'\\1', result0)\n",
    "    #print(\"result: \" + result)\n",
    "    pattern2 = re.compile(r'\\d+')\n",
    "    match2 = pattern2.search(result)\n",
    "    #print(\"match2: \" + match2.group(0))\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    result = result.translate(translator).replace(' doutor ', ' dr ').replace(\" senhor \", \" sr \").replace(\" senhora \",\" sra \").replace(\" santo \", \" s \").replace(\" santa \",\" sta \").replace(\" das \",\" \").replace(\" dos \",\" \").replace(\" do \", \" \").replace(\" da \",\" \").replace(\" de \",\" \").replace(\"  \",\" \")\n",
    "    if match2:\n",
    "        pattern3 = r'^\\D*'  \n",
    "        match3 = re.search(pattern3, result)\n",
    "        #print(\"match3: \" + match3.group())\n",
    "        return match3.group() + match2.group(0)\n",
    "    elif result:\n",
    "        return result\n",
    "\n",
    "#rnal[\"numero_porta\"] = rnal[\"Endereco\"].apply(clean_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(address, postalcode):\n",
    "    try:\n",
    "        if postalcode: \n",
    "            geocode_result = gmaps.geocode(f'{address} {postalcode} {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "        else:\n",
    "            geocode_result = gmaps.geocode(f'{address}, {city}, {country})', components={'locality': city, 'country': 'PT'})[0]\n",
    "\n",
    "        geocode_types = sum([i['types'] for i in geocode_result['address_components']], [])\n",
    "        \n",
    "        lat, lon = geocode_result['geometry']['location'].values()\n",
    "        \n",
    "        geocode_flag = not ('street_number' in geocode_types and 'route' in geocode_types)\n",
    "        polygon_flag = not city_polygon.contains(Point(lon, lat))\n",
    "        city_flag = (city_lat, city_lon) == (lat, lon)\n",
    "        \n",
    "        flag = geocode_flag or polygon_flag or city_flag\n",
    "        \n",
    "        return [lat, lon, flag]\n",
    "    except:\n",
    "        print(address)\n",
    "        print(postalcode)\n",
    "        print(city)\n",
    "        print(country)\n",
    "    return [np.nan, np.nan, True]\n",
    "\n",
    "#KEY = 'AIzaSyCIzAbRgEsMKAzkUuos4oEEaeGtSJ_Kh58'\n",
    "#gmaps = googlemaps.Client(key=KEY)\n",
    "#city = 'Porto'\n",
    "#country = 'Portugal'\n",
    "#city_polygon = Polygon(requests.get(f'https://nominatim.openstreetmap.org/search.php?q={city}+{country}&polygon_geojson=1&format=json').json()[0]['geojson']['coordinates'][0])\n",
    "#city_lat, city_lon = gmaps.geocode(f'{city}, {country})')[0]['geometry']['location'].values()\n",
    "\n",
    "#city_coordinates = rnal.progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, x.CodigoPostal), index=['lat', 'lon', 'flag']), axis=1)\n",
    "#rnal =  pd.concat([rnal[:], city_coordinates[:]], axis=\"columns\")\n",
    "\n",
    "#rnal[\"flag\"] = rnal[\"flag\"].fillna(True)\n",
    "#rnal[\"numero_porta\"] = rnal[\"numero_porta\"].apply(unidecode)\n",
    "#city_coordinates = rnal[rnal.flag].progress_apply(lambda x: pd.Series(get_coordinates(x.numero_porta, False), index=['lat', 'lon', 'flag']), axis=1)\n",
    "#for idx, row in tqdm(city_coordinates.iterrows()):\n",
    "#    rnal.loc[idx,['lat','lon','flag']] = [row.lat,row.lon,row.flag]\n",
    "\n",
    "#rnal.loc[rnal['flag'], ['lat', 'lon']] = rnal.loc[rnal['flag'], ['X', 'Y']].values\n",
    "\n",
    "\n",
    "#rnal[\"X\"] = rnal[\"lat\"].round(6)\n",
    "#rnal[\"Y\"] = rnal[\"lon\"].round(6)\n",
    "#rnal = rnal.drop(['flag', \"lat\", \"lon\"], axis=1)\n",
    "#rnal['DataAberturaPublico'] = rnal['DataAberturaPublico'].apply(lambda x: pd.to_datetime(x).date())\n",
    "#rnal['DataRegisto'] = rnal['DataRegisto'].apply(lambda x: pd.to_datetime(x).date())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Como se expandiram os ALs ao longo do tempo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnal['weight'] = rnal.groupby(['X', 'Y']).transform('size')\n",
    "min_value = rnal['weight'].min()\n",
    "max_value = rnal['weight'].max()\n",
    "rnal['weight'] = (rnal['weight'] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10463it [00:00, 26333.62it/s]\n"
     ]
    }
   ],
   "source": [
    "type_map = {'Apartamento':1,'Moradia':2,'EstabelecimentoHospedagem':3,'EstabelecimentoHospedagemHostel':4,'Quartos':5}\n",
    "freg_map = {'União das freguesias de Cedofeita, Santo Ildefonso, Sé, Miragaia, São Nicolau e Vitória':1,'Bonfim':2,'União das freguesias de Lordelo do Ouro e Massarelos':3,'Paranhos':4,'União das freguesias de Aldoar, Foz do Douro e Nevogilde':5,'Campanhã':6,'Ramalde':7}\n",
    "\n",
    "start_date = datetime(2011, 1, 1) # AL licenses start in 2011\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "geojson = {}\n",
    "geojson[\"type\"] = \"FeatureCollection\"\n",
    "geojson[\"features\"] = []\n",
    "\n",
    "for idx, single_al in tqdm(rnal.sort_values(by='DataAberturaPublico').reset_index().iterrows()):\n",
    "    al_date = datetime.strptime(single_al.DataAberturaPublico, '%Y-%m-%d')\n",
    "    al_entry = {}\n",
    "    al_entry[\"type\"] = \"Feature\"\n",
    "    al_entry[\"properties\"] = {}\n",
    "    al_entry[\"properties\"][\"id\"] = idx+1\n",
    "    al_entry[\"properties\"][\"year\"] = al_date.strftime('%y')\n",
    "    al_entry[\"properties\"][\"month\"] = al_date.strftime('%m')\n",
    "    al_entry[\"properties\"][\"type\"] = type_map[single_al.Modalidade]\n",
    "    al_entry[\"properties\"][\"ts\"] = round(min(max((al_date - start_date).days / (end_date - start_date).days, 0), 1), 2)\n",
    "    al_entry[\"properties\"][\"mega_host\"] = single_al.mega_host\n",
    "    al_entry[\"properties\"][\"freg\"] = freg_map[single_al.Freguesia]\n",
    "    al_entry[\"properties\"][\"weight\"] = single_al.weight\n",
    "    al_entry[\"geometry\"] = {}\n",
    "    al_entry[\"geometry\"][\"type\"] = \"Point\"\n",
    "    al_entry[\"geometry\"][\"coordinates\"] = [round(single_al.X,6),round(single_al.Y,6)]\n",
    "    geojson[\"features\"].append(al_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/al.json', 'w') as fp:\n",
    "    json.dump(geojson, fp, separators=(',', ':'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Ritmo de crescimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnal_dates = rnal\n",
    "\n",
    "rnal_dates['DataRegisto'] = pd.to_datetime(rnal_dates['DataRegisto'])\n",
    "rnal_dates['DataAberturaPublico'] = pd.to_datetime(rnal_dates['DataAberturaPublico'])\n",
    "\n",
    "count_registo = rnal_dates.groupby(rnal_dates['DataRegisto'].dt.year).size().reset_index(name='Registo')\n",
    "count_abertura = rnal_dates.groupby(rnal_dates['DataAberturaPublico'].dt.year).size().reset_index(name='Abertura')\n",
    "count = pd.merge(count_abertura, count_registo, how='outer', left_on='DataAberturaPublico', right_on='DataRegisto')\n",
    "count = count.fillna(0)\n",
    "\n",
    "#Gráfico de Barras - <= 2013 agregado\n",
    "count_abertura_grafico = count_abertura.set_index(\"DataAberturaPublico\")\n",
    "count_abertura_grafico.loc[2013] = count_abertura_grafico.loc[count_abertura_grafico.index < 2014].sum()\n",
    "count_abertura_grafico.loc[2024] = count_abertura_grafico.loc[count_abertura_grafico.index > 2023].sum()\n",
    "count_abertura_grafico = count_abertura_grafico.loc[(count_abertura_grafico.index >= 2013) & (count_abertura_grafico.index <= 2024)]\n",
    "count_abertura_grafico.to_json('../web/public/static/data/datas_abertura.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abertura</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataAberturaPublico</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Abertura\n",
       "DataAberturaPublico          \n",
       "2013                      254\n",
       "2014                      182\n",
       "2015                      467\n",
       "2016                      760\n",
       "2017                     1602\n",
       "2018                     1715\n",
       "2019                     1276\n",
       "2020                      606\n",
       "2021                      878\n",
       "2022                     1914\n",
       "2023                      798\n",
       "2024                       11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_abertura_grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(count['DataAberturaPublico'], count['Abertura'])\n",
    "#plt.plot(count['DataAberturaPublico'], count['Registo'], marker='o', linestyle='-', label='Registo')\n",
    "plt.title('Count')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Impactos na cidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pressão e alterações na população e nos alojamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Por secção estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/censos/BGRI.gpkg\"\n",
    "BGRI = gpd.read_file(input_file)\n",
    "BGRI = BGRI.to_crs(\"EPSG:4326\")\n",
    "points_gdf = gpd.GeoDataFrame(rnal, geometry=gpd.points_from_xy(rnal['X'], rnal['Y']), crs=\"EPSG:4326\")\n",
    "points_in_areas = gpd.sjoin(points_gdf, BGRI, how='left', op='within')\n",
    "point_counts = points_in_areas.groupby('BGRI2021').size().reset_index(name='ALs')\n",
    "merged_df = pd.merge(BGRI, point_counts, on='BGRI2021', how='left')\n",
    "merged_df['ALs'] = merged_df['ALs'].fillna(0)\n",
    "merged_df[\"ALs_ALsmaisAlojamentos\"] = merged_df[\"ALs\"] / (merged_df[\"N_ALOJAMENTOS_FAMILIARES\"] + merged_df[\"ALs\"])*100\n",
    "\n",
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "\n",
    "intersections = gpd.overlay(merged_df, CAOP11, how='intersection')\n",
    "intersections['intersection_area'] = intersections['geometry'].area\n",
    "idx = intersections.groupby('BGRI2021')['intersection_area'].idxmax()\n",
    "result_df = intersections.loc[idx, ['BGRI2021', 'FREGUESIA']]\n",
    "result_df[\"BGRI2021\"] = result_df[\"BGRI2021\"].astype(int)\n",
    "result_df = pd.DataFrame(result_df).set_index(\"BGRI2021\")\n",
    "merged_df[\"BGRI2021\"] = merged_df[\"BGRI2021\"].astype(int)\n",
    "merged_df = merged_df.set_index(\"BGRI2021\")\n",
    "result_df = result_df.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "result_df[\"Freguesia2011\"] = result_df[\"Freguesia2011\"].apply(str.title)\n",
    "merged_df = merged_df.join(result_df, on=\"BGRI2021\", how=\"left\")\n",
    "merged_df[\"Freguesia2011_code\"] = merged_df['Freguesia2011'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "pressao_json_seccao = []\n",
    "\n",
    "for idx, single_block in merged_df.reset_index().iterrows():\n",
    "    censos_entry[\"type\"] = \"Feature\"\n",
    "    censos_entry[\"geometry\"] = {}\n",
    "    censos_entry[\"geometry\"][\"type\"] = \"Polygon\"\n",
    "    censos_entry[\"geometry\"][\"coordinates\"] = shapely.wkt.dumps(single_block.geometry, rounding_precision=6)\n",
    "    censos_entry[\"properties\"] = {}\n",
    "    censos_entry[\"properties\"][\"als\"] = single_block.ALs\n",
    "    censos_entry[\"properties\"][\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"properties\"][\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"properties\"][\"freg\"] = single_block.Freguesia2011_code\n",
    "    pressao_json_seccao.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos_seccao.json', 'w') as fp:\n",
    "    json.dump(pressao_json_seccao, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Por freguesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "CAOP11 = pd.DataFrame(CAOP11)\n",
    "CAOP11[\"FREGUESIA\"] = CAOP11[\"FREGUESIA\"].apply(str.title)\n",
    "CAOP11 = CAOP11.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "CAOP11 = CAOP11.set_index(\"Freguesia2011\")\n",
    "\n",
    "freguesias21 = merged_df.groupby(\"Freguesia2011\").agg({\"Freguesia2011_code\":\"first\", \"N_INDIVIDUOS\":'sum', \"ALs\":\"sum\", \"N_ALOJAMENTOS_FAMILIARES\":\"sum\"})\n",
    "freguesias21[\"ALs_ALsmaisAlojamentos\"] = freguesias21[\"ALs\"] / (freguesias21[\"N_ALOJAMENTOS_FAMILIARES\"] + freguesias21[\"ALs\"])*100\n",
    "freguesias21 = freguesias21.join(CAOP11, on=\"Freguesia2011\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/censos/BGRI2011.gpkg\"\n",
    "BGRI11 = gpd.read_file(input_file)\n",
    "BGRI11 = BGRI11.to_crs(\"EPSG:4326\")\n",
    "input_file = \"data/geofiles/CAOP2011.shp\"\n",
    "CAOP11 = gpd.read_file(input_file)\n",
    "CAOP11 = CAOP11[CAOP11[\"MUNICIPIO\"] == \"PORTO\"][[\"FREGUESIA\", \"geometry\"]]\n",
    "CAOP11 = CAOP11.to_crs(\"EPSG:4326\")\n",
    "\n",
    "intersections = gpd.overlay(BGRI11, CAOP11, how='intersection')\n",
    "intersections['intersection_area'] = intersections['geometry'].area\n",
    "idx = intersections.groupby('BGRI11')['intersection_area'].idxmax()\n",
    "result_df = intersections.loc[idx, ['BGRI11', 'FREGUESIA']]\n",
    "result_df[\"BGRI11\"] = result_df[\"BGRI11\"].astype(int)\n",
    "result_df = pd.DataFrame(result_df).set_index(\"BGRI11\")\n",
    "BGRI11[\"BGRI11\"] = BGRI11[\"BGRI11\"].astype(int)\n",
    "BGRI11 = BGRI11.set_index(\"BGRI11\")\n",
    "result_df = result_df.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "result_df[\"Freguesia2011\"] = result_df[\"Freguesia2011\"].apply(str.title)\n",
    "BGRI11 = BGRI11.join(result_df, on=\"BGRI11\", how=\"left\")\n",
    "BGRI11[\"Freguesia2011_code\"] = BGRI11['Freguesia2011'].astype('category').cat.codes\n",
    "\n",
    "CAOP11 = pd.DataFrame(CAOP11)\n",
    "CAOP11[\"FREGUESIA\"] = CAOP11[\"FREGUESIA\"].apply(str.title)\n",
    "CAOP11 = CAOP11.rename(columns={\"FREGUESIA\":\"Freguesia2011\"})\n",
    "CAOP11 = CAOP11.set_index(\"Freguesia2011\")\n",
    "freguesias11 = BGRI11.groupby(\"Freguesia2011\").agg({\"Freguesia2011_code\":\"first\", \"N_INDIVIDUOS_RESIDENT\":'sum', \"N_ALOJAMENTOS_FAMILIARES\":\"sum\"})\n",
    "freguesias11 = freguesias11.join(CAOP11, on=\"Freguesia2011\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely \n",
    "pressao_json_freguesia = []\n",
    "\n",
    "for idx, single_block in freguesias21.reset_index().iterrows():\n",
    "    censos_entry[\"type\"] = \"Feature\"\n",
    "    censos_entry[\"geometry\"] = {}\n",
    "    censos_entry[\"geometry\"][\"type\"] = \"Polygon\"\n",
    "    censos_entry[\"geometry\"][\"coordinates\"] = shapely.wkt.dumps(single_block.geometry, rounding_precision=6)\n",
    "    censos_entry[\"properties\"] = {}\n",
    "    censos_entry[\"properties\"][\"als\"] = single_block.ALs\n",
    "    censos_entry[\"properties\"][\"individuos\"] = single_block.N_INDIVIDUOS\n",
    "    censos_entry[\"properties\"][\"propAL\"] = single_block.ALs_ALsmaisAlojamentos\n",
    "    censos_entry[\"properties\"][\"freg\"] = single_block.Freguesia2011_code\n",
    "    censos_entry[\"properties\"][\"diff_pop_2011\"] = (single_block[\"N_INDIVIDUOS\"] - freguesias11.loc[single_block.Freguesia2011][\"N_INDIVIDUOS_RESIDENT\"]) / freguesias11.loc[single_block.Freguesia2011][\"N_INDIVIDUOS_RESIDENT\"] * 100\n",
    "    censos_entry[\"properties\"][\"diff_alojamentos_2011\"] = (single_block[\"N_ALOJAMENTOS_FAMILIARES\"] - freguesias11.loc[single_block.Freguesia2011][\"N_ALOJAMENTOS_FAMILIARES\"]) / freguesias11.loc[single_block.Freguesia2011][\"N_ALOJAMENTOS_FAMILIARES\"] * 100\n",
    "    pressao_json_freguesia.append(censos_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/censos_freguesia.json', 'w') as fp:\n",
    "    json.dump(pressao_json_freguesia, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quem ganha com os ALs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Concentração económica (ALs por host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['host_listings_number'] = airbnb.groupby('host_id')['listing_url'].transform('count')\n",
    "airbnb[\"host_more_than_1_listing\"] = airbnb['host_listings_number'].apply(lambda x: x > 1)\n",
    "airbnb[\"host_more_than_2_listings\"] = airbnb['host_listings_number'].apply(lambda x: x > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_listings_count = airbnb['host_id'].value_counts().reset_index()\n",
    "host_listings_count.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts Airbnb: \" + str(host_listings_count[host_listings_count[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count[host_listings_count[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_listings_count_rnal = rnal[\"Email\"].value_counts().reset_index()\n",
    "host_listings_count_rnal.columns = ['host_id', 'listings_count']\n",
    "\n",
    "print(\"Número de hosts RNAL: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] > 0].shape[0]))\n",
    "print(\"Número de hosts com 2 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 2].shape[0]))\n",
    "print(\"Número de hosts com 3 ou mais anúncios: \" + str(host_listings_count_rnal[host_listings_count_rnal[\"listings_count\"] >= 3].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prédios com vários ALs (só funcionará quando corrermos API do Google Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnal['entradas_repetidas'] = rnal.groupby(['X', 'Y']).transform('size')\n",
    "rnal[[\"numero_porta\",\"entradas_repetidas\"]].drop_duplicates().sort_values(by=\"entradas_repetidas\", ascending=False).set_index(\"numero_porta\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnal[rnal[\"entradas_repetidas\"] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Licenças "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(text):\n",
    "    # Use regular expression to find and extract all groups of consecutive numbers\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    \n",
    "    # Find the largest group of consecutive numbers (if any)\n",
    "    if numbers:\n",
    "        largest_number = max(numbers, key=len)\n",
    "        return largest_number\n",
    "    return None\n",
    "airbnb[\"license\"] = airbnb[\"license\"].astype(str)\n",
    "airbnb['license_cleaned'] = airbnb['license'].apply(extract_code)\n",
    "airbnb[\"license_cleaned\"] = airbnb[\"license_cleaned\"].replace({\"6\":\"0\",\n",
    "\"Registo n.º: 237/2010 (4 de Maio) - Turismo Portugal\":\"237\",\n",
    "\"553/2016\":\"553\"})\n",
    "\n",
    "rnal[\"NrRNAL\"] = rnal[\"NrRNAL\"].astype(str)\n",
    "rnet[\"NrRNET\"] = rnet[\"NrRNET\"].astype(str)\n",
    "set_rnal = set(rnal[\"NrRNAL\"])\n",
    "set_rnet = set(rnet[\"NrRNET\"])\n",
    "\n",
    "def has_license(license_number):\n",
    "    if license_number in set_rnal:\n",
    "        return 'RNAL'\n",
    "    elif license_number in set_rnet:\n",
    "        return 'RNET'\n",
    "    else:\n",
    "        return 'None'\n",
    "        \n",
    "airbnb['has_license'] = airbnb['license_cleaned'].apply(has_license)\n",
    "airbnb['has_license'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anúncios sem indicação de licença: \" + str(airbnb['license_cleaned'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_RNAL = airbnb[airbnb[\"has_license\"] == \"RNAL\"][[\"license_cleaned\",\"first_review\"]]\n",
    "airbnb_with_RNAL = airbnb_with_RNAL.rename(columns={\"license_cleaned\":\"NrRNAL\"})\n",
    "\n",
    "merged_airbnb_RNAL = rnal.merge(airbnb_with_RNAL, on='NrRNAL', how='inner')\n",
    "merged_airbnb_RNAL = merged_airbnb_RNAL[~merged_airbnb_RNAL[\"first_review\"].isna()]\n",
    "merged_airbnb_RNAL.shape\n",
    "\n",
    "merged_airbnb_RNAL['DataAberturaPublico'] = pd.to_datetime(merged_airbnb_RNAL['DataAberturaPublico'])\n",
    "merged_airbnb_RNAL['first_review'] = pd.to_datetime(merged_airbnb_RNAL['first_review'])\n",
    "merged_airbnb_RNAL['first_review'] = merged_airbnb_RNAL['first_review'].dt.tz_localize('UTC')\n",
    "\n",
    "merged_airbnb_RNAL['license_date_after_review'] = merged_airbnb_RNAL['DataAberturaPublico'] > merged_airbnb_RNAL['first_review']\n",
    "merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Airbnbs com reviews anteriores à data de abertura: \" + str(merged_airbnb_RNAL[\"license_date_after_review\"].value_counts()[True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = pd.read_csv('../Hoteis/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "geojson = {}\n",
    "geojson[\"type\"] = \"FeatureCollection\"\n",
    "geojson[\"features\"] = []\n",
    "\n",
    "for idx, single_hotel in hotels.reset_index().iterrows():\n",
    "    hotel_entry = {}\n",
    "    hotel_entry[\"type\"] = \"Feature\"\n",
    "    hotel_entry[\"geometry\"] = json.loads(single_hotel.geometry.replace(\"\\'\", \"\\\"\"))\n",
    "    hotel_entry[\"properties\"] = {}\n",
    "    hotel_entry[\"properties\"][\"h\"] = single_hotel.novos_ET\n",
    "    geojson[\"features\"].append(hotel_entry)\n",
    "\n",
    "with open(f'../web/public/static/data/hotels.json', 'w') as fp:\n",
    "    json.dump(geojson, fp, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
